Published in Transactions on Machine Learning Research (10/2024) More Agents Is All You Need Junyou Li∗junyouli@tencent.com Tencent Qin Zhang∗adrienzhang@tencent.com Tencent Yangbin Yu yangbinyu@tencent.com Tencent Qiang Fu leonfu@tencent.com Tencent Deheng Ye†dericye@tencent.com Tencent Reviewed on OpenReview: https: // openreview. net/ forum? id= bgzUSZ8aeg Abstract We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of
agents instantiated. Also, this method, termed as Agent Forest, is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: https://github.com/MoreAgentsIsAllYouNeed/AgentForest. 1 Introduction Although large
language models (LLMs) demonstrate remarkable capabilities in variety of applications (Zhao et al., 2023), such as language generation, understanding, and reasoning, they struggle to provide accurate answers when faced with complicated tasks. To improve the performance of LLMs, some of recent studies focus on ensemble methods (Wang et al., 2023b; Wan et al., 2024) and multiple LLM-Agents collaboration frameworks (Du et al., 2023; Wu et al., 2023). In these works, multiple LLM agents are used to
improve the performance of LLMs. For instance, LLM-Debate Du et al. (2023) employs multiple LLM agents in a debate form. The reasoning performance is improved by creating a framework that allows more than one agent to “debate” the final answer of arithmetic tasks. They show performance improvements compared to using one single agent. Similarly, CoT-SC (Wang et al., 2023b) generates multiple thought chains and picks the most self-consistent one as the final answer. The reasoning performance is
improved by involving more thought chains compared to chain-of-thought (CoT) (Wei et al., 2022) which employs a single thought chain. Incidentally, from the data analysis of these works, we can notice the effects of putting multiple agents together, to some extent, can lead to a performance improvement in certain problems. For example, in Table 10 of Section 3.3 of LLM-Debate Du et al. (2023), the authors have reported a preliminary curve: the accuracy of a math problem increases with the
number of debating agents (although the number was simply increased from 1 to 7). Also, in Wang et al. (2023b), involving more chain-of-thought pipelines (termed as a “sample-and-marginalize” decoding procedure), can ∗Co-first authors. †Corresponding author. 1arXiv:2402.05120v2 [cs.CL] 11 Oct 2024
Published in Transactions on Machine Learning Research (10/2024) 0 5 10 15 20 25 30 35 Ensemble Size30405060708090Accuracy (%) llama-70B (single)gpt-3.5-turbo (single)gpt-4 (single)Accuracy Curves In GSM8K llama-13B llama-70B gpt-3.5-turbo Figure 1: The accuracy increases with ensemble size across Llama2-13B, Llama2-70B and GPT-3.5-Turbo in GSM8K. When the ensemble size scales up to 15, Llama2-13B achieves comparable accuracy with Llama2-70B. Similarly, When the ensemble size scales up to
15and20, Llama2-70B and GPT-3.5-Turbo achieve comparable accuracy with their more powerful counterparts. The error bars represent the standard error. lead to a performance gain. We realize that the LLM performance may likely be improved by a brute-force scaling up of the number of agents instantiated. However, since the scaling property of “raw” agents is not the focus of these works, the scenarios/tasks and experiments considered are limited. So far, there lacks a dedicated in-depth study on
such a phenomenon. Hence, a natural question arises: Does this phenomenon generally exist? To answer the research question above, we conduct the first comprehensive study on the scaling property of LLM agents. To dig out the potential of multiple agents, we propose to use a simple(st) sampling-and-voting method, which involves two phases. First, the query of the task, i.e., the input to an LLM, is iteratively fed into a single LLM, or a multiple LLM-Agents collaboration framework, to generate
multiple outputs. Subsequently, majority voting is used to determine the final result. The procedure is inspired by that of the CoT-SC, but it does not rely on designing complex CoT paths. In fact, it can be used as a plug-in to further enhance CoT-based methods, as will be shown in our evaluations. Our method is termed as Agent Forest , a tribute to the classic Random Forest (Breiman, 2001). The experiments are conducted by using various LLMs of different sizes on diverse datasets covering
reasoning and generation. The result indicates that LLM performance can generally be improved by increasing the ensemble size, i.e., the number of agents, across a wide range of tasks. Surprisingly, a brute-force ensemble of smaller LLMs can achieve comparable or superior performance to larger LLMs, with a nutshell shown in Figure 1, which will be further expanded in later sections. Moreover, by combining our method with other existing methods, we find the performance can be further improved.
By comparing with the performance of complicated methods, the result shows that employing our method solely can achieve comparable performance in most cases. This implies that comparable performance can be achieved without the need for additional handcraft prompt design or complex collaboration frameworks. Additionally, the experimental results indicate that there are greater performance improvements when addressing difficult tasks and when using weaker models. To understand the reasons behind
these performance improvements, we analyze the influence of problem difficulty on the effectiveness of our method. We classify difficulty into three dimensions: the inherent difficulty, the length of reasoning steps, and the prior probability of the correct answer. Through a series of experiments, we adjust these dimensions and observe their effects independently. We observe and summarize a few properties, based on which, we further develop optimization strategies that can intrigue the power of
“More Agents”. Our contributions are summarized as follows: 2
